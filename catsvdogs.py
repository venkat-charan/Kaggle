# -*- coding: utf-8 -*-
"""CatsvDogs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sgLw7SSKY7_CO87BdMDj1OVCXNOCtG1S
"""

import os
import zipfile
import random
import tensorflow as tf
import shutil
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile
from os import getcwd

# Commented out IPython magic to ensure Python compatibility.
path_cats_and_dogs = f"{getcwd()}/../tmp2/cats-and-dogs.zip"      # extract data
shutil.rmtree('/tmp')

local_zip = path_cats_and_dogs
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

try:
    os.makedirs("/tmp/cats-v-dogs/testing/dogs")          #Create directories to store data
    os.makedirs("/tmp/cats-v-dogs/testing/cats")
    os.makedirs("/tmp/cats-v-dogs/training/dogs")
    os.makedirs("/tmp/cats-v-dogs/training/cats")
except OSError:
    pass

def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):          #function to split data into training and testing
    num=len(os.listdir(SOURCE))
    
    files=os.listdir(SOURCE)
    testfiles=random.sample(files,round((1-SPLIT_SIZE)*num))
    
    s=set()
    for i in range(len(testfiles)):
        s.add(testfiles[i])
        
    for i in range(len(files)):
        if(os.path.getsize(os.path.join(SOURCE,files[i]))>0):
            if(files[i] in s):
                copyfile(os.path.join(SOURCE,files[i]),(os.path.join(TESTING,files[i])))
            else:
                copyfile(os.path.join(SOURCE,files[i]),(os.path.join(TRAINING,files[i])))
        


CAT_SOURCE_DIR = "/tmp/PetImages/Cat/"
TRAINING_CATS_DIR = "/tmp/cats-v-dogs/training/cats/"
TESTING_CATS_DIR = "/tmp/cats-v-dogs/testing/cats/"
DOG_SOURCE_DIR = "/tmp/PetImages/Dog/"
TRAINING_DOGS_DIR = "/tmp/cats-v-dogs/training/dogs/"
TESTING_DOGS_DIR = "/tmp/cats-v-dogs/testing/dogs/"

split_size = .9
split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)
split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)

#Model is defined below

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation='relu', input_shape=(150, 150, 3)),
                                    tf.keras.layers.MaxPool2D(2,2),
                                    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),
                                    tf.keras.layers.MaxPool2D(2,2),
                                    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),
                                    tf.keras.layers.MaxPool2D(2,2),
                                    tf.keras.layers.Flatten(),
                                    tf.keras.layers.Dense(512,activation='relu'),
                                    tf.keras.layers.Dense(1,activation='sigmoid')

])


model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])

TRAINING_DIR = "/tmp/cats-v-dogs/training/"
train_datagen = ImageDataGenerator(rescale=1./255.)

train_generator = train_datagen.flow_from_directory(TRAINING_DIR,batch_size=20,class_mode='binary',target_size=(150,150))

VALIDATION_DIR = "/tmp/cats-v-dogs/testing/"
validation_datagen = ImageDataGenerator(rescale=1./255.)

validation_generator = train_datagen.flow_from_directory(VALIDATION_DIR,batch_size=20,class_mode='binary',target_size=(150,150))


#Training Model

history = model.fit_generator(train_generator,
                              epochs=2,
                              verbose=1,
                              validation_data=validation_generator)

# PLOT LOSS AND ACCURACY
# %matplotlib inline

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc=history.history['acc']
val_acc=history.history['val_acc']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")


plt.title('Training and validation loss')

# Desired output. Charts with training and validation metrics. No crash :)